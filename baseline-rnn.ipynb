{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ImdbMovieReviews:\n",
    "    \"\"\"\n",
    "    The movie review dataset is offered by Stanford Universityâ€™s AI department:\n",
    "    http://ai.stanford.edu/~amaas/data/sentiment/. It comes as a compressed  tar  archive where\n",
    "    positive and negative reviews can be found as text files in two according folders. We apply\n",
    "    the same pre-processing to the text as in the last section: Extracting plain words using a\n",
    "    regular expression and converting to lower case.\n",
    "    \"\"\"\n",
    "    DEFAULT_URL = \\\n",
    "        'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    TOKEN_REGEX = re.compile(r'[A-Za-z]+|[!?.:,()]')\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cache_dir = './imdb'\n",
    "        self._url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "        \n",
    "        if not os.path.isfile(self._cache_dir):\n",
    "            urllib.request.urlretrieve(self._url, self._cache_dir)\n",
    "        self.filepath = self._cache_dir\n",
    "\n",
    "    def __iter__(self):\n",
    "        with tarfile.open(self.filepath) as archive:\n",
    "            items = archive.getnames()\n",
    "            for filename in archive.getnames():\n",
    "                if filename.startswith('aclImdb/train/pos/'):\n",
    "                    yield self._read(archive, filename), True\n",
    "                elif filename.startswith('aclImdb/train/neg/'):\n",
    "                    yield self._read(archive, filename), False\n",
    "                    \n",
    "    def _read(self, archive, filename):\n",
    "        with archive.extractfile(filename) as file_:\n",
    "            data = file_.read().decode('utf-8')\n",
    "            data = type(self).TOKEN_REGEX.findall(data)\n",
    "            data = [x.lower() for x in data]\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Spacy is my favourite nlp framework, which havu builtin word embeddings trains on wikipesia\n",
    "from spacy.en import English\n",
    "\n",
    "class Embedding:\n",
    "    \n",
    "    def __init__(self, length):\n",
    "#          spaCy makes using word vectors very easy. \n",
    "#             The Lexeme , Token , Span  and Doc  classes all have a .vector property,\n",
    "#             which is a 1-dimensional numpy array of 32-bit floats:\n",
    "        self.parser = English()\n",
    "        self._length = length\n",
    "        self.dimensions = 300\n",
    "        \n",
    "    def __call__(self, sequence):\n",
    "        data = np.zeros((self._length, self.dimensions))\n",
    "        # you can access known words from the parser's vocabulary\n",
    "        embedded = [self.parser.vocab[w].vector for w in sequence]\n",
    "        data[:len(sequence)] = embedded\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lazy import lazy\n",
    "\n",
    "class SequenceClassificationModel:\n",
    "    def __init__(self, data, params):\n",
    "        self.params = params\n",
    "        self._create_placeholders()\n",
    "        self.prediction\n",
    "        self.cost\n",
    "        self.error\n",
    "        self.optimize\n",
    "        self.global_step = 0\n",
    "        self._create_summaries()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _create_placeholders(self):\n",
    "        with tf.name_scope(\"data\"):\n",
    "            self.data = tf.placeholder(tf.float32, [None, self.params.seq_length, self.params.embed_length])\n",
    "            self.target = tf.placeholder(tf.float32, [None, 2])\n",
    "  \n",
    "    def _create_summaries(self):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            tf.summary.scalar('loss', self.cost)\n",
    "            tf.summary.scalar('erroe', self.error)\n",
    "            self.summary = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "    @lazy\n",
    "    def length(self):\n",
    "        with tf.name_scope(\"seq_length\"):\n",
    "            used = tf.sign(tf.reduce_max(tf.abs(self.data), reduction_indices=2))\n",
    "            length = tf.reduce_sum(used, reduction_indices=1)\n",
    "            length = tf.cast(length, tf.int32)\n",
    "        return length\n",
    "    \n",
    "    @lazy\n",
    "    def prediction(self):\n",
    "        with tf.name_scope(\"recurrent_layer\"):\n",
    "            output, _ = tf.nn.dynamic_rnn(\n",
    "                self.params.rnn_cell(self.params.rnn_hidden),\n",
    "                self.data,\n",
    "                dtype=tf.float32,\n",
    "                sequence_length=self.length\n",
    "            )\n",
    "        last = self._last_relevant(output, self.length)\n",
    "\n",
    "        with tf.name_scope(\"softmax_layer\"):\n",
    "            num_classes = int(self.target.get_shape()[1])\n",
    "            weight = tf.Variable(tf.truncated_normal(\n",
    "                [self.params.rnn_hidden, num_classes], stddev=0.01))\n",
    "            bias = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "            prediction = tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "        return prediction\n",
    "    \n",
    "    @lazy\n",
    "    def cost(self):\n",
    "        cross_entropy = -tf.reduce_sum(self.target * tf.log(self.prediction))\n",
    "        return cross_entropy\n",
    "    \n",
    "    @lazy\n",
    "    def error(self):\n",
    "        self.mistakes = tf.not_equal(\n",
    "            tf.argmax(self.target, 1), tf.argmax(self.prediction, 1))\n",
    "        return tf.reduce_mean(tf.cast(self.mistakes, tf.float32))\n",
    "    \n",
    "    @lazy\n",
    "    def optimize(self):\n",
    "        with tf.name_scope(\"optimization\"):\n",
    "            gradient = self.params.optimizer.compute_gradients(self.cost)\n",
    "            if self.params.gradient_clipping:\n",
    "                limit = self.params.gradient_clipping\n",
    "                gradient = [\n",
    "                    (tf.clip_by_value(g, -limit, limit), v)\n",
    "                    if g is not None else (None, v)\n",
    "                    for g, v in gradient]\n",
    "            optimize = self.params.optimizer.apply_gradients(gradient)\n",
    "        return optimize\n",
    "    \n",
    "    @staticmethod\n",
    "    def _last_relevant(output, length):\n",
    "        with tf.name_scope(\"last_relevant\"):\n",
    "            # As of now, TensorFlow only supports indexing along the first dimension, using\n",
    "            # tf.gather() . We thus flatten the first two dimensions of the output activations from their\n",
    "            # shape of  sequences x time_steps x word_vectors  and construct an index into this resulting tensor.\n",
    "            batch_size = tf.shape(output)[0]\n",
    "            max_length = int(output.get_shape()[1])\n",
    "            output_size = int(output.get_shape()[2])\n",
    "\n",
    "            # The index takes into account the start indices for each sequence in the flat tensor and adds\n",
    "            # the sequence length to it. Actually, we only add  length - 1  so that we select the last valid\n",
    "            # time step.\n",
    "            index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "            flat = tf.reshape(output, [-1, output_size])\n",
    "            relevant = tf.gather(flat, index)\n",
    "        return relevant\n",
    "    \n",
    "    def train(self, batches, save_prefix, save_every=10):\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir('./saved/'):\n",
    "            saver.restore(self.sess, tf.train.latest_checkpoint('./saved/'))\n",
    "        else:\n",
    "            os.makedirs('saved')\n",
    "        summary_writer = tf.summary.FileWriter('graphs/run{}'.format(self.global_step), self.sess.graph)\n",
    "        self.global_step += 1\n",
    "        for index, batch in enumerate(batches):\n",
    "            feed = {model.data: batch[0], model.target: batch[1]}\n",
    "            error, _, summary_str = self.sess.run([model.error, model.optimize, model.summary], feed)\n",
    "            print('{}: {:3.1f}%'.format(index + 1, 100 * error))\n",
    "            if index % save_every == 0:\n",
    "                summary_writer.add_summary(summary_str, index)\n",
    "                summary_writer.flush()\n",
    "            if index % save_every == 0:\n",
    "                save_path = os.path.join('checkpoints', save_prefix)\n",
    "                print('saving...', save_path)\n",
    "                saver.save(self.sess, save_path, global_step=index)\n",
    "        saver.save(self.sess, os.path.join('checkpoints', save_prefix + '_final'))\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        feed = {model.data: data, }\n",
    "        prediction = self.sess.run([model.prediction], feed)        \n",
    "        return prediction\n",
    "        \n",
    "    def close(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_batched(iterator, length, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        data = np.zeros((batch_size, length, embedding.dimensions))\n",
    "        target = np.zeros((batch_size, 2))\n",
    "        for index in range(batch_size):\n",
    "            text, label = next(iterator)\n",
    "            data[index] = embedding(text)\n",
    "            target[index] = [1, 0] if label else [0, 1]\n",
    "        yield data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = list(ImdbMovieReviews())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = max(len(x[0]) for x in reviews)\n",
    "embedding = Embedding(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from attrdict import AttrDict\n",
    "\n",
    "params = AttrDict(\n",
    "    rnn_cell=tf.contrib.rnn.GRUCell,\n",
    "    rnn_hidden=300,\n",
    "    optimizer=tf.train.RMSPropOptimizer(0.002),\n",
    "    batch_size=20,\n",
    "    gradient_clipping=100,\n",
    "    seq_length=length,\n",
    "    embed_length=embedding.dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = preprocess_batched(reviews, length, embedding, params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurbanov/Soft/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = SequenceClassificationModel(data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "2: 50.0%\n",
      "3: 65.0%\n",
      "4: 45.0%\n",
      "5: 55.0%\n",
      "6: 45.0%\n",
      "7: 60.0%\n",
      "8: 50.0%\n",
      "9: 40.0%\n",
      "10: 50.0%\n",
      "11: 45.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "12: 25.0%\n",
      "13: 50.0%\n",
      "14: 40.0%\n",
      "15: 50.0%\n",
      "16: 55.0%\n",
      "17: 55.0%\n",
      "18: 35.0%\n",
      "19: 45.0%\n",
      "20: 35.0%\n",
      "21: 55.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "22: 60.0%\n",
      "23: 45.0%\n",
      "24: 55.0%\n",
      "25: 55.0%\n",
      "26: 40.0%\n",
      "27: 45.0%\n",
      "28: 65.0%\n",
      "29: 45.0%\n",
      "30: 35.0%\n",
      "31: 50.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "32: 25.0%\n",
      "33: 35.0%\n",
      "34: 65.0%\n",
      "35: 45.0%\n",
      "36: 45.0%\n",
      "37: 50.0%\n",
      "38: 45.0%\n",
      "39: 60.0%\n",
      "40: 55.0%\n",
      "41: 60.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "42: 45.0%\n",
      "43: 70.0%\n",
      "44: 50.0%\n",
      "45: 50.0%\n",
      "46: 50.0%\n",
      "47: 60.0%\n",
      "48: 40.0%\n",
      "49: 50.0%\n",
      "50: 60.0%\n",
      "51: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "52: 45.0%\n",
      "53: 40.0%\n",
      "54: 35.0%\n",
      "55: 50.0%\n",
      "56: 70.0%\n",
      "57: 40.0%\n",
      "58: 45.0%\n",
      "59: 40.0%\n",
      "60: 45.0%\n",
      "61: 55.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "62: 45.0%\n",
      "63: 35.0%\n",
      "64: 60.0%\n",
      "65: 50.0%\n",
      "66: 15.0%\n",
      "67: 60.0%\n",
      "68: 55.0%\n",
      "69: 40.0%\n",
      "70: 40.0%\n",
      "71: 45.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "72: 50.0%\n",
      "73: 50.0%\n",
      "74: 25.0%\n",
      "75: 50.0%\n",
      "76: 35.0%\n",
      "77: 45.0%\n",
      "78: 35.0%\n",
      "79: 55.0%\n",
      "80: 50.0%\n",
      "81: 60.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "82: 55.0%\n",
      "83: 55.0%\n",
      "84: 45.0%\n",
      "85: 40.0%\n",
      "86: 25.0%\n",
      "87: 40.0%\n",
      "88: 55.0%\n",
      "89: 45.0%\n",
      "90: 45.0%\n",
      "91: 55.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "92: 45.0%\n",
      "93: 25.0%\n",
      "94: 45.0%\n",
      "95: 55.0%\n",
      "96: 60.0%\n",
      "97: 50.0%\n",
      "98: 50.0%\n",
      "99: 30.0%\n",
      "100: 25.0%\n",
      "101: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "102: 40.0%\n",
      "103: 50.0%\n",
      "104: 50.0%\n",
      "105: 40.0%\n",
      "106: 45.0%\n",
      "107: 50.0%\n",
      "108: 50.0%\n",
      "109: 35.0%\n",
      "110: 60.0%\n",
      "111: 70.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "112: 35.0%\n",
      "113: 40.0%\n",
      "114: 20.0%\n",
      "115: 45.0%\n",
      "116: 45.0%\n",
      "117: 50.0%\n",
      "118: 40.0%\n",
      "119: 40.0%\n",
      "120: 45.0%\n",
      "121: 60.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "122: 55.0%\n",
      "123: 55.0%\n",
      "124: 50.0%\n",
      "125: 30.0%\n",
      "126: 45.0%\n",
      "127: 60.0%\n",
      "128: 40.0%\n",
      "129: 40.0%\n",
      "130: 40.0%\n",
      "131: 45.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "132: 30.0%\n",
      "133: 40.0%\n",
      "134: 30.0%\n",
      "135: 40.0%\n",
      "136: 40.0%\n",
      "137: 45.0%\n",
      "138: 55.0%\n",
      "139: 30.0%\n",
      "140: 30.0%\n",
      "141: 40.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "142: 45.0%\n",
      "143: 40.0%\n",
      "144: 35.0%\n",
      "145: 45.0%\n",
      "146: 55.0%\n",
      "147: 45.0%\n",
      "148: 60.0%\n",
      "149: 50.0%\n",
      "150: 30.0%\n",
      "151: 40.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "152: 20.0%\n",
      "153: 50.0%\n",
      "154: 30.0%\n",
      "155: 60.0%\n",
      "156: 50.0%\n",
      "157: 35.0%\n",
      "158: 50.0%\n",
      "159: 65.0%\n",
      "160: 60.0%\n",
      "161: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "162: 35.0%\n",
      "163: 25.0%\n",
      "164: 35.0%\n",
      "165: 45.0%\n",
      "166: 35.0%\n",
      "167: 55.0%\n",
      "168: 50.0%\n",
      "169: 40.0%\n",
      "170: 30.0%\n",
      "171: 45.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "172: 30.0%\n",
      "173: 35.0%\n",
      "174: 55.0%\n",
      "175: 35.0%\n",
      "176: 40.0%\n",
      "177: 20.0%\n",
      "178: 50.0%\n",
      "179: 30.0%\n",
      "180: 35.0%\n",
      "181: 50.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "182: 60.0%\n",
      "183: 10.0%\n",
      "184: 45.0%\n",
      "185: 60.0%\n",
      "186: 30.0%\n",
      "187: 35.0%\n",
      "188: 45.0%\n",
      "189: 35.0%\n",
      "190: 50.0%\n",
      "191: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "192: 25.0%\n",
      "193: 45.0%\n",
      "194: 50.0%\n",
      "195: 40.0%\n",
      "196: 30.0%\n",
      "197: 20.0%\n",
      "198: 20.0%\n",
      "199: 60.0%\n",
      "200: 25.0%\n",
      "201: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "202: 10.0%\n",
      "203: 45.0%\n",
      "204: 35.0%\n",
      "205: 35.0%\n",
      "206: 40.0%\n",
      "207: 40.0%\n",
      "208: 40.0%\n",
      "209: 75.0%\n",
      "210: 40.0%\n",
      "211: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "212: 25.0%\n",
      "213: 45.0%\n",
      "214: 35.0%\n",
      "215: 45.0%\n",
      "216: 30.0%\n",
      "217: 40.0%\n",
      "218: 30.0%\n",
      "219: 35.0%\n",
      "220: 20.0%\n",
      "221: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "222: 25.0%\n",
      "223: 25.0%\n",
      "224: 35.0%\n",
      "225: 35.0%\n",
      "226: 15.0%\n",
      "227: 30.0%\n",
      "228: 40.0%\n",
      "229: 25.0%\n",
      "230: 20.0%\n",
      "231: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "232: 10.0%\n",
      "233: 20.0%\n",
      "234: 25.0%\n",
      "235: 20.0%\n",
      "236: 35.0%\n",
      "237: 25.0%\n",
      "238: 20.0%\n",
      "239: 25.0%\n",
      "240: 20.0%\n",
      "241: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "242: 25.0%\n",
      "243: 15.0%\n",
      "244: 20.0%\n",
      "245: 15.0%\n",
      "246: 15.0%\n",
      "247: 20.0%\n",
      "248: 30.0%\n",
      "249: 25.0%\n",
      "250: 15.0%\n",
      "251: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "252: 45.0%\n",
      "253: 15.0%\n",
      "254: 35.0%\n",
      "255: 25.0%\n",
      "256: 30.0%\n",
      "257: 30.0%\n",
      "258: 35.0%\n",
      "259: 15.0%\n",
      "260: 20.0%\n",
      "261: 0.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "262: 10.0%\n",
      "263: 40.0%\n",
      "264: 20.0%\n",
      "265: 20.0%\n",
      "266: 15.0%\n",
      "267: 10.0%\n",
      "268: 10.0%\n",
      "269: 25.0%\n",
      "270: 20.0%\n",
      "271: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "272: 15.0%\n",
      "273: 25.0%\n",
      "274: 35.0%\n",
      "275: 5.0%\n",
      "276: 25.0%\n",
      "277: 35.0%\n",
      "278: 20.0%\n",
      "279: 20.0%\n",
      "280: 35.0%\n",
      "281: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "282: 20.0%\n",
      "283: 25.0%\n",
      "284: 10.0%\n",
      "285: 20.0%\n",
      "286: 15.0%\n",
      "287: 25.0%\n",
      "288: 35.0%\n",
      "289: 30.0%\n",
      "290: 15.0%\n",
      "291: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "292: 30.0%\n",
      "293: 15.0%\n",
      "294: 25.0%\n",
      "295: 25.0%\n",
      "296: 25.0%\n",
      "297: 25.0%\n",
      "298: 15.0%\n",
      "299: 15.0%\n",
      "300: 20.0%\n",
      "301: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "302: 15.0%\n",
      "303: 20.0%\n",
      "304: 25.0%\n",
      "305: 20.0%\n",
      "306: 20.0%\n",
      "307: 25.0%\n",
      "308: 25.0%\n",
      "309: 15.0%\n",
      "310: 40.0%\n",
      "311: 40.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "312: 35.0%\n",
      "313: 5.0%\n",
      "314: 20.0%\n",
      "315: 40.0%\n",
      "316: 10.0%\n",
      "317: 40.0%\n",
      "318: 10.0%\n",
      "319: 10.0%\n",
      "320: 15.0%\n",
      "321: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "322: 10.0%\n",
      "323: 25.0%\n",
      "324: 10.0%\n",
      "325: 20.0%\n",
      "326: 20.0%\n",
      "327: 30.0%\n",
      "328: 25.0%\n",
      "329: 20.0%\n",
      "330: 10.0%\n",
      "331: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "332: 25.0%\n",
      "333: 20.0%\n",
      "334: 20.0%\n",
      "335: 40.0%\n",
      "336: 30.0%\n",
      "337: 20.0%\n",
      "338: 15.0%\n",
      "339: 10.0%\n",
      "340: 20.0%\n",
      "341: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "342: 25.0%\n",
      "343: 10.0%\n",
      "344: 20.0%\n",
      "345: 15.0%\n",
      "346: 20.0%\n",
      "347: 20.0%\n",
      "348: 25.0%\n",
      "349: 10.0%\n",
      "350: 5.0%\n",
      "351: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "352: 20.0%\n",
      "353: 40.0%\n",
      "354: 5.0%\n",
      "355: 5.0%\n",
      "356: 30.0%\n",
      "357: 25.0%\n",
      "358: 15.0%\n",
      "359: 30.0%\n",
      "360: 15.0%\n",
      "361: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "362: 10.0%\n",
      "363: 20.0%\n",
      "364: 30.0%\n",
      "365: 20.0%\n",
      "366: 20.0%\n",
      "367: 5.0%\n",
      "368: 15.0%\n",
      "369: 5.0%\n",
      "370: 30.0%\n",
      "371: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "372: 10.0%\n",
      "373: 15.0%\n",
      "374: 35.0%\n",
      "375: 10.0%\n",
      "376: 25.0%\n",
      "377: 20.0%\n",
      "378: 20.0%\n",
      "379: 25.0%\n",
      "380: 20.0%\n",
      "381: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "382: 5.0%\n",
      "383: 20.0%\n",
      "384: 10.0%\n",
      "385: 5.0%\n",
      "386: 20.0%\n",
      "387: 15.0%\n",
      "388: 15.0%\n",
      "389: 15.0%\n",
      "390: 10.0%\n",
      "391: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "392: 5.0%\n",
      "393: 20.0%\n",
      "394: 10.0%\n",
      "395: 15.0%\n",
      "396: 20.0%\n",
      "397: 35.0%\n",
      "398: 25.0%\n",
      "399: 15.0%\n",
      "400: 20.0%\n",
      "401: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "402: 20.0%\n",
      "403: 5.0%\n",
      "404: 20.0%\n",
      "405: 5.0%\n",
      "406: 10.0%\n",
      "407: 10.0%\n",
      "408: 35.0%\n",
      "409: 40.0%\n",
      "410: 10.0%\n",
      "411: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "412: 35.0%\n",
      "413: 15.0%\n",
      "414: 20.0%\n",
      "415: 15.0%\n",
      "416: 15.0%\n",
      "417: 25.0%\n",
      "418: 15.0%\n",
      "419: 25.0%\n",
      "420: 10.0%\n",
      "421: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "422: 15.0%\n",
      "423: 15.0%\n",
      "424: 15.0%\n",
      "425: 20.0%\n",
      "426: 20.0%\n",
      "427: 10.0%\n",
      "428: 25.0%\n",
      "429: 35.0%\n",
      "430: 25.0%\n",
      "431: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "432: 15.0%\n",
      "433: 25.0%\n",
      "434: 40.0%\n",
      "435: 15.0%\n",
      "436: 0.0%\n",
      "437: 20.0%\n",
      "438: 15.0%\n",
      "439: 0.0%\n",
      "440: 10.0%\n",
      "441: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "442: 10.0%\n",
      "443: 25.0%\n",
      "444: 25.0%\n",
      "445: 15.0%\n",
      "446: 15.0%\n",
      "447: 5.0%\n",
      "448: 15.0%\n",
      "449: 20.0%\n",
      "450: 25.0%\n",
      "451: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "452: 10.0%\n",
      "453: 15.0%\n",
      "454: 35.0%\n",
      "455: 30.0%\n",
      "456: 25.0%\n",
      "457: 20.0%\n",
      "458: 15.0%\n",
      "459: 35.0%\n",
      "460: 15.0%\n",
      "461: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "462: 15.0%\n",
      "463: 15.0%\n",
      "464: 10.0%\n",
      "465: 20.0%\n",
      "466: 20.0%\n",
      "467: 20.0%\n",
      "468: 20.0%\n",
      "469: 20.0%\n",
      "470: 30.0%\n",
      "471: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "472: 15.0%\n",
      "473: 20.0%\n",
      "474: 15.0%\n",
      "475: 15.0%\n",
      "476: 15.0%\n",
      "477: 25.0%\n",
      "478: 20.0%\n",
      "479: 20.0%\n",
      "480: 20.0%\n",
      "481: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "482: 15.0%\n",
      "483: 15.0%\n",
      "484: 25.0%\n",
      "485: 15.0%\n",
      "486: 10.0%\n",
      "487: 25.0%\n",
      "488: 15.0%\n",
      "489: 30.0%\n",
      "490: 20.0%\n",
      "491: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "492: 20.0%\n",
      "493: 20.0%\n",
      "494: 10.0%\n",
      "495: 25.0%\n",
      "496: 30.0%\n",
      "497: 20.0%\n",
      "498: 5.0%\n",
      "499: 25.0%\n",
      "500: 10.0%\n",
      "501: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "502: 15.0%\n",
      "503: 5.0%\n",
      "504: 15.0%\n",
      "505: 25.0%\n",
      "506: 10.0%\n",
      "507: 30.0%\n",
      "508: 20.0%\n",
      "509: 25.0%\n",
      "510: 25.0%\n",
      "511: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "512: 10.0%\n",
      "513: 10.0%\n",
      "514: 20.0%\n",
      "515: 15.0%\n",
      "516: 15.0%\n",
      "517: 15.0%\n",
      "518: 15.0%\n",
      "519: 15.0%\n",
      "520: 5.0%\n",
      "521: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "522: 25.0%\n",
      "523: 20.0%\n",
      "524: 20.0%\n",
      "525: 15.0%\n",
      "526: 35.0%\n",
      "527: 25.0%\n",
      "528: 5.0%\n",
      "529: 20.0%\n",
      "530: 15.0%\n",
      "531: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "532: 30.0%\n",
      "533: 30.0%\n",
      "534: 15.0%\n",
      "535: 15.0%\n",
      "536: 20.0%\n",
      "537: 20.0%\n",
      "538: 20.0%\n",
      "539: 5.0%\n",
      "540: 15.0%\n",
      "541: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "542: 15.0%\n",
      "543: 10.0%\n",
      "544: 20.0%\n",
      "545: 10.0%\n",
      "546: 20.0%\n",
      "547: 10.0%\n",
      "548: 15.0%\n",
      "549: 10.0%\n",
      "550: 10.0%\n",
      "551: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "552: 10.0%\n",
      "553: 20.0%\n",
      "554: 5.0%\n",
      "555: 10.0%\n",
      "556: 25.0%\n",
      "557: 5.0%\n",
      "558: 10.0%\n",
      "559: 30.0%\n",
      "560: 35.0%\n",
      "561: 0.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "562: 15.0%\n",
      "563: 15.0%\n",
      "564: 10.0%\n",
      "565: 25.0%\n",
      "566: 5.0%\n",
      "567: 20.0%\n",
      "568: 30.0%\n",
      "569: 10.0%\n",
      "570: 20.0%\n",
      "571: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "572: 20.0%\n",
      "573: 10.0%\n",
      "574: 20.0%\n",
      "575: 10.0%\n",
      "576: 5.0%\n",
      "577: 15.0%\n",
      "578: 25.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579: 20.0%\n",
      "580: 20.0%\n",
      "581: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "582: 20.0%\n",
      "583: 15.0%\n",
      "584: 10.0%\n",
      "585: 15.0%\n",
      "586: 0.0%\n",
      "587: 5.0%\n",
      "588: 15.0%\n",
      "589: 20.0%\n",
      "590: 10.0%\n",
      "591: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "592: 5.0%\n",
      "593: 5.0%\n",
      "594: 10.0%\n",
      "595: 10.0%\n",
      "596: 15.0%\n",
      "597: 5.0%\n",
      "598: 30.0%\n",
      "599: 15.0%\n",
      "600: 30.0%\n",
      "601: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "602: 30.0%\n",
      "603: 20.0%\n",
      "604: 15.0%\n",
      "605: 10.0%\n",
      "606: 15.0%\n",
      "607: 20.0%\n",
      "608: 10.0%\n",
      "609: 15.0%\n",
      "610: 10.0%\n",
      "611: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "612: 20.0%\n",
      "613: 0.0%\n",
      "614: 15.0%\n",
      "615: 20.0%\n",
      "616: 15.0%\n",
      "617: 25.0%\n",
      "618: 5.0%\n",
      "619: 15.0%\n",
      "620: 30.0%\n",
      "621: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "622: 25.0%\n",
      "623: 20.0%\n",
      "624: 20.0%\n",
      "625: 20.0%\n",
      "626: 20.0%\n",
      "627: 15.0%\n",
      "628: 5.0%\n",
      "629: 10.0%\n",
      "630: 0.0%\n",
      "631: 35.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "632: 15.0%\n",
      "633: 10.0%\n",
      "634: 25.0%\n",
      "635: 30.0%\n",
      "636: 10.0%\n",
      "637: 20.0%\n",
      "638: 15.0%\n",
      "639: 40.0%\n",
      "640: 25.0%\n",
      "641: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "642: 5.0%\n",
      "643: 30.0%\n",
      "644: 15.0%\n",
      "645: 10.0%\n",
      "646: 30.0%\n",
      "647: 10.0%\n",
      "648: 15.0%\n",
      "649: 15.0%\n",
      "650: 25.0%\n",
      "651: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "652: 25.0%\n",
      "653: 15.0%\n",
      "654: 30.0%\n",
      "655: 10.0%\n",
      "656: 15.0%\n",
      "657: 0.0%\n",
      "658: 10.0%\n",
      "659: 5.0%\n",
      "660: 20.0%\n",
      "661: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "662: 5.0%\n",
      "663: 5.0%\n",
      "664: 35.0%\n",
      "665: 15.0%\n",
      "666: 10.0%\n",
      "667: 10.0%\n",
      "668: 5.0%\n",
      "669: 15.0%\n",
      "670: 10.0%\n",
      "671: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "672: 10.0%\n",
      "673: 15.0%\n",
      "674: 10.0%\n",
      "675: 30.0%\n",
      "676: 5.0%\n",
      "677: 15.0%\n",
      "678: 15.0%\n",
      "679: 5.0%\n",
      "680: 10.0%\n",
      "681: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "682: 20.0%\n",
      "683: 20.0%\n",
      "684: 15.0%\n",
      "685: 15.0%\n",
      "686: 10.0%\n",
      "687: 20.0%\n",
      "688: 15.0%\n",
      "689: 10.0%\n",
      "690: 10.0%\n",
      "691: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "692: 25.0%\n",
      "693: 20.0%\n",
      "694: 25.0%\n",
      "695: 20.0%\n",
      "696: 35.0%\n",
      "697: 5.0%\n",
      "698: 10.0%\n",
      "699: 20.0%\n",
      "700: 5.0%\n",
      "701: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "702: 15.0%\n",
      "703: 15.0%\n",
      "704: 10.0%\n",
      "705: 15.0%\n",
      "706: 15.0%\n",
      "707: 20.0%\n",
      "708: 35.0%\n",
      "709: 20.0%\n",
      "710: 30.0%\n",
      "711: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "712: 25.0%\n",
      "713: 10.0%\n",
      "714: 15.0%\n",
      "715: 10.0%\n",
      "716: 0.0%\n",
      "717: 10.0%\n",
      "718: 20.0%\n",
      "719: 25.0%\n",
      "720: 0.0%\n",
      "721: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "722: 20.0%\n",
      "723: 10.0%\n",
      "724: 10.0%\n",
      "725: 15.0%\n",
      "726: 10.0%\n",
      "727: 25.0%\n",
      "728: 20.0%\n",
      "729: 10.0%\n",
      "730: 30.0%\n",
      "731: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "732: 5.0%\n",
      "733: 20.0%\n",
      "734: 15.0%\n",
      "735: 25.0%\n",
      "736: 0.0%\n",
      "737: 25.0%\n",
      "738: 10.0%\n",
      "739: 15.0%\n",
      "740: 20.0%\n",
      "741: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "742: 10.0%\n",
      "743: 15.0%\n",
      "744: 10.0%\n",
      "745: 25.0%\n",
      "746: 20.0%\n",
      "747: 25.0%\n",
      "748: 20.0%\n",
      "749: 30.0%\n",
      "750: 5.0%\n",
      "751: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "752: 15.0%\n",
      "753: 40.0%\n",
      "754: 15.0%\n",
      "755: 25.0%\n",
      "756: 5.0%\n",
      "757: 20.0%\n",
      "758: 20.0%\n",
      "759: 35.0%\n",
      "760: 15.0%\n",
      "761: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "762: 20.0%\n",
      "763: 15.0%\n",
      "764: 25.0%\n",
      "765: 25.0%\n",
      "766: 5.0%\n",
      "767: 5.0%\n",
      "768: 15.0%\n",
      "769: 10.0%\n",
      "770: 5.0%\n",
      "771: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "772: 0.0%\n",
      "773: 0.0%\n",
      "774: 20.0%\n",
      "775: 15.0%\n",
      "776: 15.0%\n",
      "777: 15.0%\n",
      "778: 20.0%\n",
      "779: 10.0%\n",
      "780: 15.0%\n",
      "781: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "782: 5.0%\n",
      "783: 15.0%\n",
      "784: 10.0%\n",
      "785: 15.0%\n",
      "786: 20.0%\n",
      "787: 10.0%\n",
      "788: 20.0%\n",
      "789: 10.0%\n",
      "790: 10.0%\n",
      "791: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "792: 20.0%\n",
      "793: 15.0%\n",
      "794: 20.0%\n",
      "795: 5.0%\n",
      "796: 30.0%\n",
      "797: 10.0%\n",
      "798: 15.0%\n",
      "799: 15.0%\n",
      "800: 30.0%\n",
      "801: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "802: 25.0%\n",
      "803: 20.0%\n",
      "804: 20.0%\n",
      "805: 15.0%\n",
      "806: 0.0%\n",
      "807: 15.0%\n",
      "808: 15.0%\n",
      "809: 10.0%\n",
      "810: 10.0%\n",
      "811: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "812: 10.0%\n",
      "813: 15.0%\n",
      "814: 35.0%\n",
      "815: 20.0%\n",
      "816: 20.0%\n",
      "817: 25.0%\n",
      "818: 20.0%\n",
      "819: 15.0%\n",
      "820: 0.0%\n",
      "821: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "822: 15.0%\n",
      "823: 25.0%\n",
      "824: 10.0%\n",
      "825: 5.0%\n",
      "826: 25.0%\n",
      "827: 15.0%\n",
      "828: 15.0%\n",
      "829: 15.0%\n",
      "830: 30.0%\n",
      "831: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "832: 10.0%\n",
      "833: 10.0%\n",
      "834: 25.0%\n",
      "835: 30.0%\n",
      "836: 5.0%\n",
      "837: 20.0%\n",
      "838: 10.0%\n",
      "839: 10.0%\n",
      "840: 20.0%\n",
      "841: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "842: 20.0%\n",
      "843: 5.0%\n",
      "844: 25.0%\n",
      "845: 20.0%\n",
      "846: 5.0%\n",
      "847: 10.0%\n",
      "848: 15.0%\n",
      "849: 10.0%\n",
      "850: 20.0%\n",
      "851: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "852: 10.0%\n",
      "853: 25.0%\n",
      "854: 25.0%\n",
      "855: 20.0%\n",
      "856: 5.0%\n",
      "857: 35.0%\n",
      "858: 15.0%\n",
      "859: 25.0%\n",
      "860: 30.0%\n",
      "861: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "862: 0.0%\n",
      "863: 10.0%\n",
      "864: 15.0%\n",
      "865: 15.0%\n",
      "866: 20.0%\n",
      "867: 5.0%\n",
      "868: 15.0%\n",
      "869: 5.0%\n",
      "870: 10.0%\n",
      "871: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "872: 10.0%\n",
      "873: 5.0%\n",
      "874: 20.0%\n",
      "875: 25.0%\n",
      "876: 15.0%\n",
      "877: 15.0%\n",
      "878: 20.0%\n",
      "879: 15.0%\n",
      "880: 15.0%\n",
      "881: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "882: 25.0%\n",
      "883: 30.0%\n",
      "884: 20.0%\n",
      "885: 5.0%\n",
      "886: 10.0%\n",
      "887: 30.0%\n",
      "888: 10.0%\n",
      "889: 30.0%\n",
      "890: 20.0%\n",
      "891: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "892: 10.0%\n",
      "893: 15.0%\n",
      "894: 5.0%\n",
      "895: 20.0%\n",
      "896: 25.0%\n",
      "897: 10.0%\n",
      "898: 25.0%\n",
      "899: 15.0%\n",
      "900: 25.0%\n",
      "901: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "902: 10.0%\n",
      "903: 25.0%\n",
      "904: 10.0%\n",
      "905: 15.0%\n",
      "906: 35.0%\n",
      "907: 15.0%\n",
      "908: 25.0%\n",
      "909: 5.0%\n",
      "910: 20.0%\n",
      "911: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "912: 10.0%\n",
      "913: 25.0%\n",
      "914: 15.0%\n",
      "915: 15.0%\n",
      "916: 25.0%\n",
      "917: 25.0%\n",
      "918: 30.0%\n",
      "919: 10.0%\n",
      "920: 25.0%\n",
      "921: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "922: 10.0%\n",
      "923: 20.0%\n",
      "924: 25.0%\n",
      "925: 15.0%\n",
      "926: 15.0%\n",
      "927: 10.0%\n",
      "928: 10.0%\n",
      "929: 10.0%\n",
      "930: 25.0%\n",
      "931: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "932: 15.0%\n",
      "933: 10.0%\n",
      "934: 25.0%\n",
      "935: 15.0%\n",
      "936: 30.0%\n",
      "937: 10.0%\n",
      "938: 10.0%\n",
      "939: 5.0%\n",
      "940: 20.0%\n",
      "941: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "942: 20.0%\n",
      "943: 25.0%\n",
      "944: 5.0%\n",
      "945: 0.0%\n",
      "946: 10.0%\n",
      "947: 20.0%\n",
      "948: 5.0%\n",
      "949: 5.0%\n",
      "950: 15.0%\n",
      "951: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "952: 20.0%\n",
      "953: 5.0%\n",
      "954: 15.0%\n",
      "955: 20.0%\n",
      "956: 10.0%\n",
      "957: 0.0%\n",
      "958: 15.0%\n",
      "959: 15.0%\n",
      "960: 20.0%\n",
      "961: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "962: 10.0%\n",
      "963: 30.0%\n",
      "964: 20.0%\n",
      "965: 10.0%\n",
      "966: 5.0%\n",
      "967: 35.0%\n",
      "968: 10.0%\n",
      "969: 25.0%\n",
      "970: 0.0%\n",
      "971: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "972: 5.0%\n",
      "973: 10.0%\n",
      "974: 20.0%\n",
      "975: 15.0%\n",
      "976: 30.0%\n",
      "977: 30.0%\n",
      "978: 25.0%\n",
      "979: 20.0%\n",
      "980: 5.0%\n",
      "981: 30.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "982: 15.0%\n",
      "983: 25.0%\n",
      "984: 15.0%\n",
      "985: 20.0%\n",
      "986: 0.0%\n",
      "987: 10.0%\n",
      "988: 25.0%\n",
      "989: 5.0%\n",
      "990: 10.0%\n",
      "991: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "992: 10.0%\n",
      "993: 20.0%\n",
      "994: 5.0%\n",
      "995: 5.0%\n",
      "996: 5.0%\n",
      "997: 15.0%\n",
      "998: 10.0%\n",
      "999: 0.0%\n",
      "1000: 20.0%\n",
      "1001: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1002: 15.0%\n",
      "1003: 25.0%\n",
      "1004: 10.0%\n",
      "1005: 20.0%\n",
      "1006: 15.0%\n",
      "1007: 15.0%\n",
      "1008: 10.0%\n",
      "1009: 5.0%\n",
      "1010: 15.0%\n",
      "1011: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1012: 15.0%\n",
      "1013: 5.0%\n",
      "1014: 20.0%\n",
      "1015: 10.0%\n",
      "1016: 15.0%\n",
      "1017: 10.0%\n",
      "1018: 5.0%\n",
      "1019: 25.0%\n",
      "1020: 15.0%\n",
      "1021: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1022: 20.0%\n",
      "1023: 30.0%\n",
      "1024: 15.0%\n",
      "1025: 5.0%\n",
      "1026: 25.0%\n",
      "1027: 30.0%\n",
      "1028: 10.0%\n",
      "1029: 15.0%\n",
      "1030: 15.0%\n",
      "1031: 40.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1032: 10.0%\n",
      "1033: 5.0%\n",
      "1034: 25.0%\n",
      "1035: 10.0%\n",
      "1036: 10.0%\n",
      "1037: 5.0%\n",
      "1038: 0.0%\n",
      "1039: 5.0%\n",
      "1040: 30.0%\n",
      "1041: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1042: 20.0%\n",
      "1043: 10.0%\n",
      "1044: 30.0%\n",
      "1045: 15.0%\n",
      "1046: 15.0%\n",
      "1047: 15.0%\n",
      "1048: 25.0%\n",
      "1049: 5.0%\n",
      "1050: 5.0%\n",
      "1051: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1052: 10.0%\n",
      "1053: 30.0%\n",
      "1054: 25.0%\n",
      "1055: 15.0%\n",
      "1056: 15.0%\n",
      "1057: 15.0%\n",
      "1058: 15.0%\n",
      "1059: 15.0%\n",
      "1060: 0.0%\n",
      "1061: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1062: 15.0%\n",
      "1063: 5.0%\n",
      "1064: 15.0%\n",
      "1065: 15.0%\n",
      "1066: 10.0%\n",
      "1067: 25.0%\n",
      "1068: 20.0%\n",
      "1069: 20.0%\n",
      "1070: 10.0%\n",
      "1071: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1072: 25.0%\n",
      "1073: 5.0%\n",
      "1074: 10.0%\n",
      "1075: 15.0%\n",
      "1076: 10.0%\n",
      "1077: 20.0%\n",
      "1078: 20.0%\n",
      "1079: 20.0%\n",
      "1080: 15.0%\n",
      "1081: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1082: 10.0%\n",
      "1083: 5.0%\n",
      "1084: 10.0%\n",
      "1085: 25.0%\n",
      "1086: 10.0%\n",
      "1087: 0.0%\n",
      "1088: 10.0%\n",
      "1089: 20.0%\n",
      "1090: 5.0%\n",
      "1091: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1092: 25.0%\n",
      "1093: 10.0%\n",
      "1094: 0.0%\n",
      "1095: 20.0%\n",
      "1096: 10.0%\n",
      "1097: 20.0%\n",
      "1098: 10.0%\n",
      "1099: 5.0%\n",
      "1100: 40.0%\n",
      "1101: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1102: 15.0%\n",
      "1103: 10.0%\n",
      "1104: 15.0%\n",
      "1105: 20.0%\n",
      "1106: 15.0%\n",
      "1107: 15.0%\n",
      "1108: 10.0%\n",
      "1109: 5.0%\n",
      "1110: 15.0%\n",
      "1111: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1112: 15.0%\n",
      "1113: 15.0%\n",
      "1114: 10.0%\n",
      "1115: 20.0%\n",
      "1116: 20.0%\n",
      "1117: 15.0%\n",
      "1118: 15.0%\n",
      "1119: 20.0%\n",
      "1120: 15.0%\n",
      "1121: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1122: 0.0%\n",
      "1123: 0.0%\n",
      "1124: 10.0%\n",
      "1125: 25.0%\n",
      "1126: 15.0%\n",
      "1127: 15.0%\n",
      "1128: 25.0%\n",
      "1129: 5.0%\n",
      "1130: 0.0%\n",
      "1131: 25.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1132: 15.0%\n",
      "1133: 15.0%\n",
      "1134: 20.0%\n",
      "1135: 30.0%\n",
      "1136: 35.0%\n",
      "1137: 25.0%\n",
      "1138: 15.0%\n",
      "1139: 10.0%\n",
      "1140: 35.0%\n",
      "1141: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1142: 10.0%\n",
      "1143: 15.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144: 10.0%\n",
      "1145: 10.0%\n",
      "1146: 15.0%\n",
      "1147: 10.0%\n",
      "1148: 10.0%\n",
      "1149: 20.0%\n",
      "1150: 5.0%\n",
      "1151: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1152: 20.0%\n",
      "1153: 5.0%\n",
      "1154: 10.0%\n",
      "1155: 30.0%\n",
      "1156: 20.0%\n",
      "1157: 20.0%\n",
      "1158: 20.0%\n",
      "1159: 20.0%\n",
      "1160: 20.0%\n",
      "1161: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1162: 15.0%\n",
      "1163: 0.0%\n",
      "1164: 15.0%\n",
      "1165: 20.0%\n",
      "1166: 5.0%\n",
      "1167: 20.0%\n",
      "1168: 20.0%\n",
      "1169: 20.0%\n",
      "1170: 20.0%\n",
      "1171: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1172: 30.0%\n",
      "1173: 15.0%\n",
      "1174: 10.0%\n",
      "1175: 30.0%\n",
      "1176: 10.0%\n",
      "1177: 5.0%\n",
      "1178: 10.0%\n",
      "1179: 30.0%\n",
      "1180: 30.0%\n",
      "1181: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1182: 0.0%\n",
      "1183: 5.0%\n",
      "1184: 5.0%\n",
      "1185: 10.0%\n",
      "1186: 5.0%\n",
      "1187: 0.0%\n",
      "1188: 15.0%\n",
      "1189: 25.0%\n",
      "1190: 20.0%\n",
      "1191: 10.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1192: 5.0%\n",
      "1193: 5.0%\n",
      "1194: 15.0%\n",
      "1195: 15.0%\n",
      "1196: 15.0%\n",
      "1197: 20.0%\n",
      "1198: 5.0%\n",
      "1199: 20.0%\n",
      "1200: 10.0%\n",
      "1201: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1202: 0.0%\n",
      "1203: 5.0%\n",
      "1204: 20.0%\n",
      "1205: 25.0%\n",
      "1206: 15.0%\n",
      "1207: 15.0%\n",
      "1208: 10.0%\n",
      "1209: 15.0%\n",
      "1210: 5.0%\n",
      "1211: 20.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1212: 5.0%\n",
      "1213: 10.0%\n",
      "1214: 15.0%\n",
      "1215: 10.0%\n",
      "1216: 10.0%\n",
      "1217: 10.0%\n",
      "1218: 20.0%\n",
      "1219: 10.0%\n",
      "1220: 10.0%\n",
      "1221: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1222: 15.0%\n",
      "1223: 30.0%\n",
      "1224: 25.0%\n",
      "1225: 10.0%\n",
      "1226: 15.0%\n",
      "1227: 10.0%\n",
      "1228: 20.0%\n",
      "1229: 25.0%\n",
      "1230: 15.0%\n",
      "1231: 15.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1232: 25.0%\n",
      "1233: 20.0%\n",
      "1234: 5.0%\n",
      "1235: 25.0%\n",
      "1236: 15.0%\n",
      "1237: 20.0%\n",
      "1238: 10.0%\n",
      "1239: 15.0%\n",
      "1240: 25.0%\n",
      "1241: 5.0%\n",
      "saving... checlkpoints/simple-rnn\n",
      "1242: 15.0%\n",
      "1243: 15.0%\n",
      "1244: 20.0%\n",
      "1245: 25.0%\n",
      "1246: 0.0%\n",
      "1247: 20.0%\n",
      "1248: 10.0%\n",
      "1249: 5.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurbanov/Soft/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:120: DeprecationWarning: generator 'preprocess_batched' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "model.train(batches, save_prefix='simple-rnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
