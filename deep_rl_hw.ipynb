{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: fill empty spaces in the following agent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepQAgent:\n",
    "    def __init__(self, state_size, action_size, render=False):\n",
    "        # Tip: if you are training this on AWS the best way is to turn off rendering\n",
    "        # and load it later with the serialized model\n",
    "        self.render = render\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.005\n",
    "        self.epsilon_decay = (self.epsilon - self.epsilon_min) / 50000\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        # replay memory\n",
    "        self.memory = deque(maxlen=10000)\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Use tflearn to get simple NN for deep q-learning\n",
    "        # Spoler alert: a couple of fully connected hidden layers should be enough\n",
    "        # Output layer should have the same dimensionality as the action space\n",
    "        # TODO\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu', input_dim = self.state_size))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(self.action_size))\n",
    "        model.compile(optimizer = Adam(lr=self.learning_rate), loss=\"mse\")\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\"Update your target model to the model you are currently learning at regular time intervals\"\"\"\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"The choice of action uses the epsilon-greedy policy for the current network.\"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    def replay_memory(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save <s, a, r, s'> to replay_memory\"\"\"\n",
    "        if action == 2:\n",
    "            action = 1\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon -= self.epsilon_decay\n",
    "            # print(len(self.memory))\n",
    "\n",
    "    def train_replay(self):\n",
    "        \"\"\"Random sampling of batch_size samples from replay memory\"\"\"\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        update_input = np.zeros((batch_size, self.state_size))\n",
    "        update_target = np.zeros((batch_size, self.action_size))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            state, action, reward, next_state, done = mini_batch[i]\n",
    "            target = self.model.predict(state)[0]\n",
    "\n",
    "            # As in queuing, it gets the maximum Q Value at s'. However, it is imported from the target model.\n",
    "            if done:\n",
    "                target[action] = reward\n",
    "            else:\n",
    "                target[action] = reward + self.discount_factor * \\\n",
    "                                          np.amax(self.target_model.predict(next_state)[0])\n",
    "            update_input[i] = state\n",
    "            update_target[i] = target\n",
    "\n",
    "        # You can create a minibatch of the correct target answer and the current value of your own,\n",
    "        self.model.fit(update_input, update_target, batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    def load_model(self, name):\n",
    "        # TODO\n",
    "        self.model.load_model(name)\n",
    "\n",
    "    def save_model(self, name):\n",
    "        # TODO\n",
    "        self.model.save(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "state_size = env.observation_space.shape[0] # should be equal 2\n",
    "ACTION_SIZE = 2\n",
    "agent = DeepQAgent(state_size, ACTION_SIZE)\n",
    "# agent.load_model(\"./save_model/<your_saved_model_name>\")\n",
    "scores, episodes = [], []\n",
    "N_EPISODES = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48671628  0.        ]]\n",
      "episode: 0   score: -200.0   memory length: 200   epsilon: 0.9960200000000077\n",
      "[[-0.58571944  0.        ]]\n",
      "episode: 1   score: -200.0   memory length: 400   epsilon: 0.9920400000000154\n",
      "[[-0.45345973  0.        ]]\n",
      "episode: 2   score: -200.0   memory length: 600   epsilon: 0.988060000000023\n",
      "[[-0.40139476  0.        ]]\n",
      "episode: 3   score: -200.0   memory length: 800   epsilon: 0.9840800000000307\n",
      "[[-0.5104905  0.       ]]\n",
      "episode: 4   score: -200.0   memory length: 1000   epsilon: 0.9801000000000384\n",
      "[[-0.57890589  0.        ]]\n",
      "episode: 5   score: -200.0   memory length: 1200   epsilon: 0.9761200000000461\n",
      "[[-0.55384785  0.        ]]\n",
      "episode: 6   score: -200.0   memory length: 1400   epsilon: 0.9721400000000537\n",
      "[[-0.47016958  0.        ]]\n",
      "episode: 7   score: -200.0   memory length: 1600   epsilon: 0.9681600000000614\n",
      "[[-0.49560149  0.        ]]\n",
      "episode: 8   score: -200.0   memory length: 1800   epsilon: 0.9641800000000691\n",
      "[[-0.42931667  0.        ]]\n",
      "episode: 9   score: -200.0   memory length: 2000   epsilon: 0.9602000000000768\n",
      "[[-0.59125062  0.        ]]\n",
      "episode: 10   score: -200.0   memory length: 2200   epsilon: 0.9562200000000844\n",
      "[[-0.43572446  0.        ]]\n",
      "episode: 11   score: -200.0   memory length: 2400   epsilon: 0.9522400000000921\n",
      "[[-0.59231772  0.        ]]\n",
      "episode: 12   score: -200.0   memory length: 2600   epsilon: 0.9482600000000998\n",
      "[[-0.57404177  0.        ]]\n",
      "episode: 13   score: -200.0   memory length: 2800   epsilon: 0.9442800000001075\n",
      "[[-0.44015485  0.        ]]\n",
      "episode: 14   score: -200.0   memory length: 3000   epsilon: 0.9403000000001152\n",
      "[[-0.44768645  0.        ]]\n",
      "episode: 15   score: -200.0   memory length: 3200   epsilon: 0.9363200000001228\n",
      "[[-0.55883861  0.        ]]\n",
      "episode: 16   score: -200.0   memory length: 3400   epsilon: 0.9323400000001305\n",
      "[[-0.47651052  0.        ]]\n",
      "episode: 17   score: -200.0   memory length: 3600   epsilon: 0.9283600000001382\n",
      "[[-0.40771122  0.        ]]\n",
      "episode: 18   score: -200.0   memory length: 3800   epsilon: 0.9243800000001459\n",
      "[[-0.4331098  0.       ]]\n",
      "episode: 19   score: -200.0   memory length: 4000   epsilon: 0.9204000000001535\n",
      "[[-0.58543727  0.        ]]\n",
      "episode: 20   score: -200.0   memory length: 4200   epsilon: 0.9164200000001612\n",
      "[[-0.5593267  0.       ]]\n",
      "episode: 21   score: -200.0   memory length: 4400   epsilon: 0.9124400000001689\n",
      "[[-0.57798055  0.        ]]\n",
      "episode: 22   score: -200.0   memory length: 4600   epsilon: 0.9084600000001766\n",
      "[[-0.45857794  0.        ]]\n",
      "episode: 23   score: -200.0   memory length: 4800   epsilon: 0.9044800000001842\n",
      "[[-0.40720078  0.        ]]\n",
      "episode: 24   score: -200.0   memory length: 5000   epsilon: 0.9005000000001919\n",
      "[[-0.47836885  0.        ]]\n",
      "episode: 25   score: -200.0   memory length: 5200   epsilon: 0.8965200000001996\n",
      "[[-0.44096243  0.        ]]\n",
      "episode: 26   score: -200.0   memory length: 5400   epsilon: 0.8925400000002073\n",
      "[[-0.54732876  0.        ]]\n",
      "episode: 27   score: -200.0   memory length: 5600   epsilon: 0.888560000000215\n",
      "[[-0.41980491  0.        ]]\n",
      "episode: 28   score: -200.0   memory length: 5800   epsilon: 0.8845800000002226\n",
      "[[-0.45266817  0.        ]]\n",
      "episode: 29   score: -200.0   memory length: 6000   epsilon: 0.8806000000002303\n",
      "[[-0.5264167  0.       ]]\n",
      "episode: 30   score: -200.0   memory length: 6200   epsilon: 0.876620000000238\n",
      "[[-0.48748697  0.        ]]\n",
      "episode: 31   score: -200.0   memory length: 6400   epsilon: 0.8726400000002457\n",
      "[[-0.54587291  0.        ]]\n",
      "episode: 32   score: -200.0   memory length: 6600   epsilon: 0.8686600000002533\n",
      "[[-0.52723391  0.        ]]\n",
      "episode: 33   score: -200.0   memory length: 6800   epsilon: 0.864680000000261\n",
      "[[-0.56778007  0.        ]]\n",
      "episode: 34   score: -200.0   memory length: 7000   epsilon: 0.8607000000002687\n",
      "[[-0.53008856  0.        ]]\n",
      "episode: 35   score: -200.0   memory length: 7200   epsilon: 0.8567200000002764\n",
      "[[-0.445658  0.      ]]\n",
      "episode: 36   score: -200.0   memory length: 7400   epsilon: 0.852740000000284\n",
      "[[-0.52237035  0.        ]]\n",
      "episode: 37   score: -200.0   memory length: 7600   epsilon: 0.8487600000002917\n",
      "[[-0.48035651  0.        ]]\n",
      "episode: 38   score: -200.0   memory length: 7800   epsilon: 0.8447800000002994\n",
      "[[-0.49148359  0.        ]]\n",
      "episode: 39   score: -200.0   memory length: 8000   epsilon: 0.8408000000003071\n",
      "[[-0.57845186  0.        ]]\n",
      "episode: 40   score: -200.0   memory length: 8200   epsilon: 0.8368200000003148\n",
      "[[-0.44974498  0.        ]]\n",
      "episode: 41   score: -200.0   memory length: 8400   epsilon: 0.8328400000003224\n",
      "[[-0.58737374  0.        ]]\n",
      "episode: 42   score: -200.0   memory length: 8600   epsilon: 0.8288600000003301\n",
      "[[-0.43954605  0.        ]]\n",
      "episode: 43   score: -200.0   memory length: 8800   epsilon: 0.8248800000003378\n",
      "[[-0.56301097  0.        ]]\n",
      "episode: 44   score: -200.0   memory length: 9000   epsilon: 0.8209000000003455\n",
      "[[-0.5701953  0.       ]]\n",
      "episode: 45   score: -200.0   memory length: 9200   epsilon: 0.8169200000003531\n",
      "[[-0.405212  0.      ]]\n",
      "episode: 46   score: -200.0   memory length: 9400   epsilon: 0.8129400000003608\n",
      "[[-0.435485  0.      ]]\n",
      "episode: 47   score: -200.0   memory length: 9600   epsilon: 0.8089600000003685\n",
      "[[-0.58768935  0.        ]]\n",
      "episode: 48   score: -200.0   memory length: 9800   epsilon: 0.8049800000003762\n",
      "[[-0.58478655  0.        ]]\n",
      "episode: 49   score: -200.0   memory length: 10000   epsilon: 0.8010000000003838\n",
      "[[-0.43723982  0.        ]]\n",
      "episode: 50   score: -200.0   memory length: 10000   epsilon: 0.7970200000003915\n",
      "[[-0.52087705  0.        ]]\n",
      "episode: 51   score: -200.0   memory length: 10000   epsilon: 0.7930400000003992\n",
      "[[-0.564477  0.      ]]\n",
      "episode: 52   score: -200.0   memory length: 10000   epsilon: 0.7890600000004069\n",
      "[[-0.48121893  0.        ]]\n",
      "episode: 53   score: -200.0   memory length: 10000   epsilon: 0.7850800000004146\n",
      "[[-0.5475371  0.       ]]\n",
      "episode: 54   score: -200.0   memory length: 10000   epsilon: 0.7811000000004222\n",
      "[[-0.41475626  0.        ]]\n",
      "episode: 55   score: -200.0   memory length: 10000   epsilon: 0.7771200000004299\n",
      "[[-0.57468405  0.        ]]\n",
      "episode: 56   score: -200.0   memory length: 10000   epsilon: 0.7731400000004376\n",
      "[[-0.55024653  0.        ]]\n",
      "episode: 57   score: -200.0   memory length: 10000   epsilon: 0.7691600000004453\n",
      "[[-0.54360052  0.        ]]\n",
      "episode: 58   score: -200.0   memory length: 10000   epsilon: 0.7651800000004529\n",
      "[[-0.41436317  0.        ]]\n",
      "episode: 59   score: -200.0   memory length: 10000   epsilon: 0.7612000000004606\n",
      "[[-0.40191886  0.        ]]\n",
      "episode: 60   score: -200.0   memory length: 10000   epsilon: 0.7572200000004683\n",
      "[[-0.51709798  0.        ]]\n",
      "episode: 61   score: -200.0   memory length: 10000   epsilon: 0.753240000000476\n",
      "[[-0.58269699  0.        ]]\n",
      "episode: 62   score: -200.0   memory length: 10000   epsilon: 0.7492600000004837\n",
      "[[-0.58317821  0.        ]]\n",
      "episode: 63   score: -200.0   memory length: 10000   epsilon: 0.7452800000004913\n",
      "[[-0.43458568  0.        ]]\n",
      "episode: 64   score: -193.0   memory length: 10000   epsilon: 0.7414393000004987\n",
      "[[-0.41416058  0.        ]]\n",
      "episode: 65   score: -200.0   memory length: 10000   epsilon: 0.7374593000005064\n",
      "[[-0.44939474  0.        ]]\n",
      "episode: 66   score: -200.0   memory length: 10000   epsilon: 0.7334793000005141\n",
      "[[-0.47778377  0.        ]]\n",
      "episode: 67   score: -200.0   memory length: 10000   epsilon: 0.7294993000005218\n",
      "[[-0.46291151  0.        ]]\n",
      "episode: 68   score: -200.0   memory length: 10000   epsilon: 0.7255193000005294\n",
      "[[-0.54001853  0.        ]]\n",
      "episode: 69   score: -200.0   memory length: 10000   epsilon: 0.7215393000005371\n",
      "[[-0.59811507  0.        ]]\n",
      "episode: 70   score: -200.0   memory length: 10000   epsilon: 0.7175593000005448\n",
      "[[-0.51000561  0.        ]]\n",
      "episode: 71   score: -200.0   memory length: 10000   epsilon: 0.7135793000005525\n",
      "[[-0.46207844  0.        ]]\n",
      "episode: 72   score: -200.0   memory length: 10000   epsilon: 0.7095993000005602\n",
      "[[-0.43107929  0.        ]]\n",
      "episode: 73   score: -200.0   memory length: 10000   epsilon: 0.7056193000005678\n",
      "[[-0.50756524  0.        ]]\n",
      "episode: 74   score: -200.0   memory length: 10000   epsilon: 0.7016393000005755\n",
      "[[-0.40753354  0.        ]]\n",
      "episode: 75   score: -200.0   memory length: 10000   epsilon: 0.6976593000005832\n",
      "[[-0.45949262  0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 76   score: -200.0   memory length: 10000   epsilon: 0.6936793000005909\n",
      "[[-0.53853868  0.        ]]\n",
      "episode: 77   score: -200.0   memory length: 10000   epsilon: 0.6896993000005985\n",
      "[[-0.46640477  0.        ]]\n",
      "episode: 78   score: -200.0   memory length: 10000   epsilon: 0.6857193000006062\n",
      "[[-0.56747364  0.        ]]\n",
      "episode: 79   score: -200.0   memory length: 10000   epsilon: 0.6817393000006139\n",
      "[[-0.55809304  0.        ]]\n",
      "episode: 80   score: -200.0   memory length: 10000   epsilon: 0.6777593000006216\n",
      "[[-0.58020558  0.        ]]\n",
      "episode: 81   score: -200.0   memory length: 10000   epsilon: 0.6737793000006292\n",
      "[[-0.57401484  0.        ]]\n",
      "episode: 82   score: -200.0   memory length: 10000   epsilon: 0.6697993000006369\n",
      "[[-0.49760603  0.        ]]\n",
      "episode: 83   score: -200.0   memory length: 10000   epsilon: 0.6658193000006446\n",
      "[[-0.46539941  0.        ]]\n",
      "episode: 84   score: -200.0   memory length: 10000   epsilon: 0.6618393000006523\n",
      "[[-0.55367165  0.        ]]\n",
      "episode: 85   score: -200.0   memory length: 10000   epsilon: 0.65785930000066\n",
      "[[-0.49564457  0.        ]]\n",
      "episode: 86   score: -183.0   memory length: 10000   epsilon: 0.654217600000667\n",
      "[[-0.41947595  0.        ]]\n",
      "episode: 87   score: -200.0   memory length: 10000   epsilon: 0.6502376000006747\n",
      "[[-0.40765985  0.        ]]\n",
      "episode: 88   score: -200.0   memory length: 10000   epsilon: 0.6462576000006823\n",
      "[[-0.54881762  0.        ]]\n",
      "episode: 89   score: -200.0   memory length: 10000   epsilon: 0.64227760000069\n",
      "[[-0.53263413  0.        ]]\n",
      "episode: 90   score: -200.0   memory length: 10000   epsilon: 0.6382976000006977\n",
      "[[-0.40617924  0.        ]]\n",
      "episode: 91   score: -200.0   memory length: 10000   epsilon: 0.6343176000007054\n",
      "[[-0.57401208  0.        ]]\n",
      "episode: 92   score: -200.0   memory length: 10000   epsilon: 0.630337600000713\n",
      "[[-0.45994367  0.        ]]\n",
      "episode: 93   score: -164.0   memory length: 10000   epsilon: 0.6270740000007193\n",
      "[[-0.51480544  0.        ]]\n",
      "episode: 94   score: -200.0   memory length: 10000   epsilon: 0.623094000000727\n",
      "[[-0.59729272  0.        ]]\n",
      "episode: 95   score: -200.0   memory length: 10000   epsilon: 0.6191140000007347\n",
      "[[-0.47797342  0.        ]]\n",
      "episode: 96   score: -200.0   memory length: 10000   epsilon: 0.6151340000007424\n",
      "[[-0.41902814  0.        ]]\n",
      "episode: 97   score: -200.0   memory length: 10000   epsilon: 0.61115400000075\n",
      "[[-0.54988299  0.        ]]\n",
      "episode: 98   score: -200.0   memory length: 10000   epsilon: 0.6071740000007577\n",
      "[[-0.57493079  0.        ]]\n",
      "episode: 99   score: -200.0   memory length: 10000   epsilon: 0.6031940000007654\n",
      "[[-0.45523701  0.        ]]\n",
      "episode: 100   score: -200.0   memory length: 10000   epsilon: 0.5992140000007731\n",
      "[[-0.49309513  0.        ]]\n",
      "episode: 101   score: -200.0   memory length: 10000   epsilon: 0.5952340000007807\n",
      "[[-0.52983968  0.        ]]\n",
      "episode: 102   score: -200.0   memory length: 10000   epsilon: 0.5912540000007884\n",
      "[[-0.52786138  0.        ]]\n",
      "episode: 103   score: -200.0   memory length: 10000   epsilon: 0.5872740000007961\n",
      "[[-0.58971615  0.        ]]\n",
      "episode: 104   score: -200.0   memory length: 10000   epsilon: 0.5832940000008038\n",
      "[[-0.54336524  0.        ]]\n",
      "episode: 105   score: -200.0   memory length: 10000   epsilon: 0.5793140000008115\n",
      "[[-0.59974615  0.        ]]\n",
      "episode: 106   score: -200.0   memory length: 10000   epsilon: 0.5753340000008191\n",
      "[[-0.59464489  0.        ]]\n",
      "episode: 107   score: -200.0   memory length: 10000   epsilon: 0.5713540000008268\n",
      "[[-0.42645879  0.        ]]\n",
      "episode: 108   score: -200.0   memory length: 10000   epsilon: 0.5673740000008345\n",
      "[[-0.48238348  0.        ]]\n",
      "episode: 109   score: -200.0   memory length: 10000   epsilon: 0.5633940000008422\n",
      "[[-0.45056431  0.        ]]\n",
      "episode: 110   score: -200.0   memory length: 10000   epsilon: 0.5594140000008498\n",
      "[[-0.55742886  0.        ]]\n",
      "episode: 111   score: -200.0   memory length: 10000   epsilon: 0.5554340000008575\n",
      "[[-0.52507589  0.        ]]\n",
      "episode: 112   score: -200.0   memory length: 10000   epsilon: 0.5514540000008652\n",
      "[[-0.55372534  0.        ]]\n",
      "episode: 113   score: -192.0   memory length: 10000   epsilon: 0.5476332000008726\n",
      "[[-0.52222503  0.        ]]\n",
      "episode: 114   score: -200.0   memory length: 10000   epsilon: 0.5436532000008802\n",
      "[[-0.44373538  0.        ]]\n",
      "episode: 115   score: -200.0   memory length: 10000   epsilon: 0.5396732000008879\n",
      "[[-0.46534909  0.        ]]\n",
      "episode: 116   score: -200.0   memory length: 10000   epsilon: 0.5356932000008956\n",
      "[[-0.54471867  0.        ]]\n",
      "episode: 117   score: -200.0   memory length: 10000   epsilon: 0.5317132000009033\n",
      "[[-0.53714751  0.        ]]\n",
      "episode: 118   score: -200.0   memory length: 10000   epsilon: 0.527733200000911\n",
      "[[-0.47705172  0.        ]]\n",
      "episode: 119   score: -200.0   memory length: 10000   epsilon: 0.5237532000009186\n",
      "[[-0.58518557  0.        ]]\n",
      "episode: 120   score: -135.0   memory length: 10000   epsilon: 0.5210667000009238\n",
      "[[-0.44143611  0.        ]]\n",
      "episode: 121   score: -200.0   memory length: 10000   epsilon: 0.5170867000009315\n",
      "[[-0.51039994  0.        ]]\n",
      "episode: 122   score: -200.0   memory length: 10000   epsilon: 0.5131067000009392\n",
      "[[-0.48128656  0.        ]]\n",
      "episode: 123   score: -143.0   memory length: 10000   epsilon: 0.5102610000009447\n",
      "[[-0.42341759  0.        ]]\n",
      "episode: 124   score: -186.0   memory length: 10000   epsilon: 0.5065596000009518\n",
      "[[-0.53269278  0.        ]]\n",
      "episode: 125   score: -200.0   memory length: 10000   epsilon: 0.5025796000009595\n",
      "[[-0.41667782  0.        ]]\n",
      "episode: 126   score: -200.0   memory length: 10000   epsilon: 0.4985996000009632\n",
      "[[-0.4573432  0.       ]]\n",
      "episode: 127   score: -200.0   memory length: 10000   epsilon: 0.4946196000009598\n",
      "[[-0.42112956  0.        ]]\n",
      "episode: 128   score: -192.0   memory length: 10000   epsilon: 0.4907988000009565\n",
      "[[-0.40847956  0.        ]]\n",
      "episode: 129   score: -185.0   memory length: 10000   epsilon: 0.4871173000009533\n",
      "[[-0.49288269  0.        ]]\n",
      "episode: 130   score: -200.0   memory length: 10000   epsilon: 0.4831373000009499\n",
      "[[-0.42850231  0.        ]]\n",
      "episode: 131   score: -200.0   memory length: 10000   epsilon: 0.4791573000009465\n",
      "[[-0.55935847  0.        ]]\n",
      "episode: 132   score: -200.0   memory length: 10000   epsilon: 0.47517730000094305\n",
      "[[-0.54873408  0.        ]]\n",
      "episode: 133   score: -174.0   memory length: 10000   epsilon: 0.47171470000094007\n",
      "[[-0.51669108  0.        ]]\n",
      "episode: 134   score: -160.0   memory length: 10000   epsilon: 0.46853070000093733\n",
      "[[-0.52918413  0.        ]]\n",
      "episode: 135   score: -187.0   memory length: 10000   epsilon: 0.4648094000009341\n",
      "[[-0.57109238  0.        ]]\n",
      "episode: 136   score: -200.0   memory length: 10000   epsilon: 0.4608294000009307\n",
      "[[-0.5609166  0.       ]]\n",
      "episode: 137   score: -200.0   memory length: 10000   epsilon: 0.4568494000009273\n",
      "[[-0.48666838  0.        ]]\n",
      "episode: 138   score: -162.0   memory length: 10000   epsilon: 0.4536256000009245\n",
      "[[-0.45020615  0.        ]]\n",
      "episode: 139   score: -158.0   memory length: 10000   epsilon: 0.4504814000009218\n",
      "[[-0.50821901  0.        ]]\n",
      "episode: 140   score: -200.0   memory length: 10000   epsilon: 0.44650140000091837\n",
      "[[-0.53656915  0.        ]]\n",
      "episode: 141   score: -200.0   memory length: 10000   epsilon: 0.44252140000091494\n",
      "[[-0.40164817  0.        ]]\n",
      "episode: 142   score: -161.0   memory length: 10000   epsilon: 0.4393175000009122\n",
      "[[-0.54645068  0.        ]]\n",
      "episode: 143   score: -200.0   memory length: 10000   epsilon: 0.43533750000090876\n",
      "[[-0.54196684  0.        ]]\n",
      "episode: 144   score: -200.0   memory length: 10000   epsilon: 0.43135750000090534\n",
      "[[-0.57888675  0.        ]]\n",
      "episode: 145   score: -200.0   memory length: 10000   epsilon: 0.4273775000009019\n",
      "[[-0.49927481  0.        ]]\n",
      "episode: 146   score: -200.0   memory length: 10000   epsilon: 0.4233975000008985\n",
      "[[-0.46997926  0.        ]]\n",
      "episode: 147   score: -200.0   memory length: 10000   epsilon: 0.41941750000089506\n",
      "[[-0.42573218  0.        ]]\n",
      "episode: 148   score: -190.0   memory length: 10000   epsilon: 0.4156365000008918\n",
      "[[-0.58417143  0.        ]]\n",
      "episode: 149   score: -200.0   memory length: 10000   epsilon: 0.4116565000008884\n",
      "[[-0.58849871  0.        ]]\n",
      "episode: 150   score: -200.0   memory length: 10000   epsilon: 0.40767650000088496\n",
      "[[-0.59742926  0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 151   score: -200.0   memory length: 10000   epsilon: 0.40369650000088153\n",
      "[[-0.40686147  0.        ]]\n",
      "episode: 152   score: -200.0   memory length: 10000   epsilon: 0.3997165000008781\n",
      "[[-0.53539603  0.        ]]\n",
      "episode: 153   score: -200.0   memory length: 10000   epsilon: 0.3957365000008747\n",
      "[[-0.57253645  0.        ]]\n",
      "episode: 154   score: -200.0   memory length: 10000   epsilon: 0.39175650000087126\n",
      "[[-0.51188932  0.        ]]\n",
      "episode: 155   score: -200.0   memory length: 10000   epsilon: 0.38777650000086783\n",
      "[[-0.41602122  0.        ]]\n",
      "episode: 156   score: -200.0   memory length: 10000   epsilon: 0.3837965000008644\n",
      "[[-0.53358417  0.        ]]\n",
      "episode: 157   score: -200.0   memory length: 10000   epsilon: 0.379816500000861\n",
      "[[-0.4924847  0.       ]]\n",
      "episode: 158   score: -200.0   memory length: 10000   epsilon: 0.37583650000085755\n",
      "[[-0.50352566  0.        ]]\n",
      "episode: 159   score: -200.0   memory length: 10000   epsilon: 0.37185650000085413\n",
      "[[-0.56974749  0.        ]]\n",
      "episode: 160   score: -200.0   memory length: 10000   epsilon: 0.3678765000008507\n",
      "[[-0.50564898  0.        ]]\n",
      "episode: 161   score: -164.0   memory length: 10000   epsilon: 0.3646129000008479\n",
      "[[-0.45351811  0.        ]]\n",
      "episode: 162   score: -150.0   memory length: 10000   epsilon: 0.3616279000008453\n",
      "[[-0.52475951  0.        ]]\n",
      "episode: 163   score: -200.0   memory length: 10000   epsilon: 0.3576479000008419\n",
      "[[-0.48171273  0.        ]]\n",
      "episode: 164   score: -148.0   memory length: 10000   epsilon: 0.35470270000083937\n",
      "[[-0.54258139  0.        ]]\n",
      "episode: 165   score: -200.0   memory length: 10000   epsilon: 0.35072270000083594\n",
      "[[-0.4816185  0.       ]]\n",
      "episode: 166   score: -152.0   memory length: 10000   epsilon: 0.34769790000083334\n",
      "[[-0.59496045  0.        ]]\n",
      "episode: 167   score: -200.0   memory length: 10000   epsilon: 0.3437179000008299\n",
      "[[-0.51390228  0.        ]]\n",
      "episode: 168   score: -170.0   memory length: 10000   epsilon: 0.340334900000827\n",
      "[[-0.5179  0.    ]]\n",
      "episode: 169   score: -200.0   memory length: 10000   epsilon: 0.3363549000008236\n",
      "[[-0.41261646  0.        ]]\n",
      "episode: 170   score: -200.0   memory length: 10000   epsilon: 0.33237490000082015\n",
      "[[-0.42638898  0.        ]]\n",
      "episode: 171   score: -200.0   memory length: 10000   epsilon: 0.3283949000008167\n",
      "[[-0.4957995  0.       ]]\n",
      "episode: 172   score: -200.0   memory length: 10000   epsilon: 0.3244149000008133\n",
      "[[-0.53411046  0.        ]]\n",
      "episode: 173   score: -200.0   memory length: 10000   epsilon: 0.3204349000008099\n",
      "[[-0.58539679  0.        ]]\n",
      "episode: 174   score: -200.0   memory length: 10000   epsilon: 0.31645490000080645\n",
      "[[-0.42534752  0.        ]]\n",
      "episode: 175   score: -154.0   memory length: 10000   epsilon: 0.3133903000008038\n",
      "[[-0.46152161  0.        ]]\n",
      "episode: 176   score: -164.0   memory length: 10000   epsilon: 0.310126700000801\n",
      "[[-0.58715452  0.        ]]\n",
      "episode: 177   score: -181.0   memory length: 10000   epsilon: 0.3065248000007979\n",
      "[[-0.56768804  0.        ]]\n",
      "episode: 178   score: -200.0   memory length: 10000   epsilon: 0.3025448000007945\n",
      "[[-0.46460122  0.        ]]\n",
      "episode: 179   score: -167.0   memory length: 10000   epsilon: 0.2992215000007916\n",
      "[[-0.42927434  0.        ]]\n",
      "episode: 180   score: -153.0   memory length: 10000   epsilon: 0.296176800000789\n",
      "[[-0.57287267  0.        ]]\n",
      "episode: 181   score: -154.0   memory length: 10000   epsilon: 0.29311220000078636\n",
      "[[-0.44237709  0.        ]]\n",
      "episode: 182   score: -200.0   memory length: 10000   epsilon: 0.28913220000078294\n",
      "[[-0.45874509  0.        ]]\n",
      "episode: 183   score: -200.0   memory length: 10000   epsilon: 0.2851522000007795\n",
      "[[-0.55921682  0.        ]]\n",
      "episode: 184   score: -148.0   memory length: 10000   epsilon: 0.282207000000777\n",
      "[[-0.50194288  0.        ]]\n",
      "episode: 185   score: -154.0   memory length: 10000   epsilon: 0.27914240000077434\n",
      "[[-0.50786697  0.        ]]\n",
      "episode: 186   score: -167.0   memory length: 10000   epsilon: 0.2758191000007715\n",
      "[[-0.46849086  0.        ]]\n",
      "episode: 187   score: -153.0   memory length: 10000   epsilon: 0.27277440000076886\n",
      "[[-0.42058591  0.        ]]\n",
      "episode: 188   score: -152.0   memory length: 10000   epsilon: 0.26974960000076625\n",
      "[[-0.54575168  0.        ]]\n",
      "episode: 189   score: -200.0   memory length: 10000   epsilon: 0.26576960000076283\n",
      "[[-0.45544301  0.        ]]\n",
      "episode: 190   score: -200.0   memory length: 10000   epsilon: 0.2617896000007594\n",
      "[[-0.55080268  0.        ]]\n",
      "episode: 191   score: -200.0   memory length: 10000   epsilon: 0.257809600000756\n",
      "[[-0.45503129  0.        ]]\n",
      "episode: 192   score: -159.0   memory length: 10000   epsilon: 0.25464550000075326\n",
      "[[-0.48051491  0.        ]]\n",
      "episode: 193   score: -166.0   memory length: 10000   epsilon: 0.2513421000007504\n",
      "[[-0.56512681  0.        ]]\n",
      "episode: 194   score: -142.0   memory length: 10000   epsilon: 0.24851630000075006\n",
      "[[-0.40275097  0.        ]]\n",
      "episode: 195   score: -173.0   memory length: 10000   epsilon: 0.2450736000007519\n",
      "[[-0.54477915  0.        ]]\n",
      "episode: 196   score: -157.0   memory length: 10000   epsilon: 0.24194930000075357\n",
      "[[-0.50087521  0.        ]]\n",
      "episode: 197   score: -163.0   memory length: 10000   epsilon: 0.2387056000007553\n",
      "[[-0.47438669  0.        ]]\n",
      "episode: 198   score: -153.0   memory length: 10000   epsilon: 0.23566090000075693\n",
      "[[-0.59545139  0.        ]]\n",
      "episode: 199   score: -138.0   memory length: 10000   epsilon: 0.2329147000007584\n",
      "[[-0.48730216  0.        ]]\n",
      "episode: 200   score: -189.0   memory length: 10000   epsilon: 0.2291536000007604\n",
      "[[-0.55574734  0.        ]]\n",
      "episode: 201   score: -144.0   memory length: 10000   epsilon: 0.22628800000076194\n",
      "[[-0.41195457  0.        ]]\n",
      "episode: 202   score: -166.0   memory length: 10000   epsilon: 0.2229846000007637\n",
      "[[-0.40126288  0.        ]]\n",
      "episode: 203   score: -170.0   memory length: 10000   epsilon: 0.2196016000007655\n",
      "[[-0.55105426  0.        ]]\n",
      "episode: 204   score: -143.0   memory length: 10000   epsilon: 0.21675590000076703\n",
      "[[-0.59524309  0.        ]]\n",
      "episode: 205   score: -151.0   memory length: 10000   epsilon: 0.21375100000076863\n",
      "[[-0.52808218  0.        ]]\n",
      "episode: 206   score: -161.0   memory length: 10000   epsilon: 0.21054710000077034\n",
      "[[-0.49290681  0.        ]]\n",
      "episode: 207   score: -152.0   memory length: 10000   epsilon: 0.20752230000077196\n",
      "[[-0.58729771  0.        ]]\n",
      "episode: 208   score: -120.0   memory length: 10000   epsilon: 0.20513430000077323\n",
      "[[-0.57767169  0.        ]]\n",
      "episode: 209   score: -200.0   memory length: 10000   epsilon: 0.20115430000077536\n",
      "[[-0.57543484  0.        ]]\n",
      "episode: 210   score: -148.0   memory length: 10000   epsilon: 0.19820910000077693\n",
      "[[-0.48823961  0.        ]]\n",
      "episode: 211   score: -156.0   memory length: 10000   epsilon: 0.1951047000007786\n",
      "[[-0.56427962  0.        ]]\n",
      "episode: 212   score: -153.0   memory length: 10000   epsilon: 0.19206000000078022\n",
      "[[-0.48836893  0.        ]]\n",
      "episode: 213   score: -133.0   memory length: 10000   epsilon: 0.18941330000078163\n",
      "[[-0.55245937  0.        ]]\n",
      "episode: 214   score: -147.0   memory length: 10000   epsilon: 0.1864880000007832\n",
      "[[-0.51216371  0.        ]]\n",
      "episode: 215   score: -164.0   memory length: 10000   epsilon: 0.18322440000078494\n",
      "[[-0.53871681  0.        ]]\n",
      "episode: 216   score: -194.0   memory length: 10000   epsilon: 0.179363800000787\n",
      "[[-0.4504248  0.       ]]\n",
      "episode: 217   score: -173.0   memory length: 10000   epsilon: 0.17592110000078884\n",
      "[[-0.54811217  0.        ]]\n",
      "episode: 218   score: -131.0   memory length: 10000   epsilon: 0.17331420000079023\n",
      "[[-0.47044591  0.        ]]\n",
      "episode: 219   score: -160.0   memory length: 10000   epsilon: 0.17013020000079193\n",
      "[[-0.59752256  0.        ]]\n",
      "episode: 220   score: -137.0   memory length: 10000   epsilon: 0.1674039000007934\n",
      "[[-0.45799205  0.        ]]\n",
      "episode: 221   score: -137.0   memory length: 10000   epsilon: 0.16467760000079484\n",
      "[[-0.53935557  0.        ]]\n",
      "episode: 222   score: -125.0   memory length: 10000   epsilon: 0.16219010000079617\n",
      "[[-0.42576522  0.        ]]\n",
      "episode: 223   score: -145.0   memory length: 10000   epsilon: 0.1593046000007977\n",
      "[[-0.40552977  0.        ]]\n",
      "episode: 224   score: -156.0   memory length: 10000   epsilon: 0.15620020000079937\n",
      "[[-0.46802161  0.        ]]\n",
      "episode: 225   score: -145.0   memory length: 10000   epsilon: 0.1533147000008009\n",
      "[[-0.57508695  0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 226   score: -200.0   memory length: 10000   epsilon: 0.14933470000080304\n",
      "[[-0.48897888  0.        ]]\n",
      "episode: 227   score: -155.0   memory length: 10000   epsilon: 0.1462502000008047\n",
      "[[-0.55162787  0.        ]]\n",
      "episode: 228   score: -169.0   memory length: 10000   epsilon: 0.14288710000080648\n",
      "[[-0.56069233  0.        ]]\n",
      "episode: 229   score: -122.0   memory length: 10000   epsilon: 0.14045930000080778\n",
      "[[-0.56242878  0.        ]]\n",
      "episode: 230   score: -115.0   memory length: 10000   epsilon: 0.138170800000809\n",
      "[[-0.5010188  0.       ]]\n",
      "episode: 231   score: -159.0   memory length: 10000   epsilon: 0.1350067000008107\n",
      "[[-0.47686057  0.        ]]\n",
      "episode: 232   score: -137.0   memory length: 10000   epsilon: 0.13228040000081215\n",
      "[[-0.50783547  0.        ]]\n",
      "episode: 233   score: -149.0   memory length: 10000   epsilon: 0.12931530000081373\n",
      "[[-0.56570942  0.        ]]\n",
      "episode: 234   score: -200.0   memory length: 10000   epsilon: 0.12533530000081586\n",
      "[[-0.56805909  0.        ]]\n",
      "episode: 235   score: -118.0   memory length: 10000   epsilon: 0.1229871000008157\n",
      "[[-0.41386242  0.        ]]\n",
      "episode: 236   score: -93.0   memory length: 10000   epsilon: 0.1211364000008154\n",
      "[[-0.43224859  0.        ]]\n",
      "episode: 237   score: -152.0   memory length: 10000   epsilon: 0.1181116000008149\n",
      "[[-0.58377828  0.        ]]\n",
      "episode: 238   score: -139.0   memory length: 10000   epsilon: 0.11534550000081445\n",
      "[[-0.58572137  0.        ]]\n",
      "episode: 239   score: -116.0   memory length: 10000   epsilon: 0.11303710000081407\n",
      "[[-0.40736045  0.        ]]\n",
      "episode: 240   score: -194.0   memory length: 10000   epsilon: 0.10917650000081344\n",
      "[[-0.53970218  0.        ]]\n",
      "episode: 241   score: -153.0   memory length: 10000   epsilon: 0.10613180000081295\n",
      "[[-0.46676018  0.        ]]\n",
      "episode: 242   score: -158.0   memory length: 10000   epsilon: 0.10298760000081243\n",
      "[[-0.4879471  0.       ]]\n",
      "episode: 243   score: -165.0   memory length: 10000   epsilon: 0.0997041000008119\n",
      "[[-0.48402985  0.        ]]\n",
      "episode: 244   score: -176.0   memory length: 10000   epsilon: 0.09620170000081132\n",
      "[[-0.46937641  0.        ]]\n",
      "episode: 245   score: -197.0   memory length: 10000   epsilon: 0.09228140000081068\n",
      "[[-0.44829321  0.        ]]\n",
      "episode: 246   score: -90.0   memory length: 10000   epsilon: 0.09049040000081039\n",
      "[[-0.46881705  0.        ]]\n",
      "episode: 247   score: -198.0   memory length: 10000   epsilon: 0.08655020000080975\n",
      "[[-0.44458145  0.        ]]\n",
      "episode: 248   score: -160.0   memory length: 10000   epsilon: 0.08336620000080923\n",
      "[[-0.46734839  0.        ]]\n",
      "episode: 249   score: -157.0   memory length: 10000   epsilon: 0.08024190000080872\n",
      "[[-0.55520398  0.        ]]\n",
      "episode: 250   score: -155.0   memory length: 10000   epsilon: 0.07715740000080822\n",
      "[[-0.44717812  0.        ]]\n",
      "episode: 251   score: -94.0   memory length: 10000   epsilon: 0.07528680000080791\n",
      "[[-0.40498991  0.        ]]\n",
      "episode: 252   score: -84.0   memory length: 10000   epsilon: 0.07361520000080764\n",
      "[[-0.46082666  0.        ]]\n",
      "episode: 253   score: -158.0   memory length: 10000   epsilon: 0.07047100000080712\n",
      "[[-0.42357265  0.        ]]\n",
      "episode: 254   score: -90.0   memory length: 10000   epsilon: 0.06868000000080683\n",
      "[[-0.45234078  0.        ]]\n",
      "episode: 255   score: -160.0   memory length: 10000   epsilon: 0.06549600000080631\n",
      "[[-0.4899651  0.       ]]\n",
      "episode: 256   score: -159.0   memory length: 10000   epsilon: 0.062331900000805796\n",
      "[[-0.53600548  0.        ]]\n",
      "episode: 257   score: -150.0   memory length: 10000   epsilon: 0.05934690000080531\n",
      "[[-0.52153205  0.        ]]\n",
      "episode: 258   score: -157.0   memory length: 10000   epsilon: 0.0562226000008048\n",
      "[[-0.59040508  0.        ]]\n",
      "episode: 259   score: -200.0   memory length: 10000   epsilon: 0.05224260000080415\n",
      "[[-0.44769584  0.        ]]\n",
      "episode: 260   score: -169.0   memory length: 10000   epsilon: 0.0488795000008036\n",
      "[[-0.53031833  0.        ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d16a25458c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Continue to learn every time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-69f27e597975>\u001b[0m in \u001b[0;36mtrain_replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_factor\u001b[0m \u001b[0;34m*\u001b[0m                                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mupdate_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mupdate_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1575\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m                                     check_batch_axis=False)\n\u001b[0;32m-> 1577\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                 raise ValueError('In a stateful network, '\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mstateful\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1925\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stateful'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(N_EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    print(state)\n",
    "\n",
    "    # Action 0 (left), 1 (do nothing), 3 (declare fake_action to avoid doing nothing\n",
    "    fake_action = 0\n",
    "\n",
    "    # Counter for the same action 4 times\n",
    "    action_count = 0\n",
    "\n",
    "    while not done:\n",
    "        if agent.render:\n",
    "            env.render()\n",
    "\n",
    "        # Select an action in the current state and proceed to a step\n",
    "        action_count = action_count + 1\n",
    "\n",
    "        if action_count == 4:\n",
    "            action = agent.get_action(state)\n",
    "            action_count = 0\n",
    "\n",
    "            if action == 0:\n",
    "                fake_action = 0\n",
    "            elif action == 1:\n",
    "                fake_action = 2\n",
    "\n",
    "        # Take 1 step with the selected action\n",
    "        next_state, reward, done, info = env.step(fake_action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        # Give a penalty of -100 for actions that end an episode\n",
    "        # reward = reward if not done else -100\n",
    "\n",
    "        # Save <s, a, r, s'> to replay memory\n",
    "        agent.replay_memory(state, fake_action, reward, next_state, done)\n",
    "        # Continue to learn every time step\n",
    "        agent.train_replay()\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            env.reset()\n",
    "            # Copy the learning model for each episode to the target model\n",
    "            agent.update_target_model()\n",
    "\n",
    "            # For each episode, the time step where cartpole stood is plot\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\", len(agent.memory),\n",
    "                  \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "    # Save model for every 50 episodes\n",
    "    if e % 50 == 0:\n",
    "        agent.save_model(\"./save_model/model_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
